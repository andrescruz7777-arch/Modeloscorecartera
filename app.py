import streamlit as st
import pandas as pd

# ==========================
# üìÇ PASO 1: CARGA DE DATOS
# ==========================

st.title("üìà Paso 1 ‚Äî Carga y Exploraci√≥n de Datos (Enero a Septiembre)")

st.markdown("""
Sube las dos bases en formato **Excel (.xlsx)**:
- Base de **enero a marzo**
- Base de **abril a septiembre**
""")

# Cargar archivos
file_ene_mar = st.file_uploader("üìò Cargar archivo Enero-Marzo", type=["xlsx"])
file_abr_sep = st.file_uploader("üìó Cargar archivo Abril-Septiembre", type=["xlsx"])

if file_ene_mar and file_abr_sep:
    # Leer los archivos
    df_ene_mar = pd.read_excel(file_ene_mar)
    df_abr_sep = pd.read_excel(file_abr_sep)

    st.subheader("üß© Vista previa Enero-Marzo")
    st.dataframe(df_ene_mar.head())

    st.subheader("üß© Vista previa Abril-Septiembre")
    st.dataframe(df_abr_sep.head())

    # Mostrar diferencias en columnas
    col_diff_1 = set(df_ene_mar.columns) - set(df_abr_sep.columns)
    col_diff_2 = set(df_abr_sep.columns) - set(df_ene_mar.columns)

    st.markdown("### üîç Comparaci√≥n de columnas entre bases")
    st.write("**En enero-marzo pero no en abril-septiembre:**", col_diff_1)
    st.write("**En abril-septiembre pero no en enero-marzo:**", col_diff_2)

    # Unificar
    df_unificado = pd.concat([df_ene_mar, df_abr_sep], ignore_index=True, sort=False)

    st.markdown("### ‚úÖ Base unificada")
    st.write("Filas totales:", df_unificado.shape[0])
    st.write("Columnas totales:", df_unificado.shape[1])
    st.dataframe(df_unificado.head())

    # Guardar en sesi√≥n para siguientes pasos
    st.session_state["df_unificado"] = df_unificado
else:
    st.info("‚¨ÜÔ∏è Sube ambos archivos para iniciar la exploraci√≥n.")
     # ------------------------------
    #üß© Paso 2 ‚Äî Limpieza y Transformaci√≥n de Datos
    # ------------------------------
st.title("üß© Paso 2 ‚Äî Limpieza y Transformaci√≥n de Datos (Versi√≥n Final)")

# =====================================
#  Recuperar el DataFrame unificado
# =====================================
if "df_unificado" not in st.session_state:
    st.warning("‚ö†Ô∏è Primero completa el Paso 1 (Carga de datos).")
else:
    df = st.session_state["df_unificado"].copy()

    # ------------------------------
    # 1Ô∏è‚É£ Estandarizar nombres de columnas
    # ------------------------------
    df.columns = (
        df.columns.str.strip()
                  .str.lower()
                  .str.replace(" ", "_")
                  .str.replace("[^a-z0-9_]", "", regex=True)
    )

    # ------------------------------
    # 2Ô∏è‚É£ Eliminar columna "sand" si existe
    # ------------------------------
    if "sand" in df.columns:
        df = df.drop(columns=["sand"])
        st.info("üßπ Columna 'sand' eliminada correctamente.")

    # ------------------------------
    # 3Ô∏è‚É£ Agregar columnas faltantes (de abril-septiembre)
    # ------------------------------
    columnas_nuevas = [
        "a√±o_pase_juridico",
        "mes_pase_juridico",
        "ciclo_mora_ini",
        "cod_convenio",
        "nom_convenio"
    ]

    for col in columnas_nuevas:
        if col not in df.columns:
            df[col] = None

    # ------------------------------
    # 4Ô∏è‚É£ Correcci√≥n de caracteres especiales (encoding)
    # ------------------------------
def limpiar_texto(texto):
    if pd.isna(texto):
        return texto
    try:
        texto = str(texto).encode("utf-8", "ignore").decode("utf-8", "ignore")
        texto = (
            texto.replace("‚àö√´", "√ë")
            .replace("‚àö¬±", "√±")
            .replace("‚àö¬©", "√©")
            .replace("‚àö¬°", "√°")
            .replace("‚àö¬≥", "√≥")
            .replace("‚àö¬∫", "√∫")
        )
        texto = unicodedata.normalize("NFKD", texto)
        return texto.strip()
    except Exception:
        return str(texto)

    # ------------------------------
    # 5Ô∏è‚É£ Validar tipos de datos b√°sicos
    # ------------------------------
    columnas_numericas = [c for c in df.columns if any(x in c for x in ["monto", "valor", "saldo", "cuota"])]
    for col in columnas_numericas:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # ------------------------------
    # 6Ô∏è‚É£ Mostrar resumen de la limpieza
    # ------------------------------
    st.subheader("üìä Vista previa del DataFrame limpio")
    st.dataframe(df.head(10), use_container_width=True)

    st.markdown("### üìã Columnas finales:")
    st.write(list(df.columns))

    st.markdown("### üìà Resumen estad√≠stico (variables num√©ricas)")
    st.dataframe(df.describe())

    # ------------------------------
    # 7Ô∏è‚É£ Guardar resultado final
    # ------------------------------
    st.session_state["df_limpio"] = df
    st.success("‚úÖ Base lista y guardada como `df_limpio` para el siguiente paso (an√°lisis exploratorio o modelo).")
    # ------------------------------
    # PASO 3
    # ------------------------------
st.title("üìä Paso 3 ‚Äî An√°lisis Exploratorio de Datos (EDA)")

# ‚úÖ Recuperar DataFrame limpio si existe o volver a generarlo desde el unificado
if "df_limpio" not in st.session_state:
    if "df_unificado" in st.session_state:
        st.session_state["df_limpio"] = st.session_state["df_unificado"].copy()
        st.warning("‚ö†Ô∏è Se restaur√≥ la base desde df_unificado. Ejecuta nuevamente el Paso 2 si a√∫n no aplicaste la limpieza final.")
else:
    df = st.session_state["df_limpio"]

    # =========================
    # üîç 1Ô∏è‚É£ Resumen General
    # =========================
    st.subheader("üìã Informaci√≥n General del DataFrame")
    st.write(f"Filas totales: **{df.shape[0]:,}**")
    st.write(f"Columnas totales: **{df.shape[1]:,}**")

    st.dataframe(df.describe(include="all").transpose())

    # =========================
    # ‚ö†Ô∏è 2Ô∏è‚É£ Valores Nulos
    # =========================
    st.subheader("üö® Valores Nulos por Columna")
    nulos = df.isnull().sum().sort_values(ascending=False)
    st.bar_chart(nulos)

    # =========================
    # üìà 3Ô∏è‚É£ Distribuci√≥n de Variables Num√©ricas
    # =========================
    st.subheader("üìà Distribuci√≥n de Variables Num√©ricas")

    columnas_numericas = df.select_dtypes(include=["int64", "float64"]).columns.tolist()

    if columnas_numericas:
        columna = st.selectbox("Selecciona una variable num√©rica para graficar:", columnas_numericas)
        fig, ax = plt.subplots()
        ax.hist(df[columna].dropna(), bins=30)
        ax.set_title(f"Distribuci√≥n de {columna}")
        st.pyplot(fig)
    else:
        st.info("No se encontraron variables num√©ricas para graficar.")

    # =========================
    # üîó 4Ô∏è‚É£ Correlaciones
    # =========================
    st.subheader("üîó Correlaciones entre Variables Num√©ricas")

    if len(columnas_numericas) >= 2:
        corr = df[columnas_numericas].corr()
        st.dataframe(corr)

        fig, ax = plt.subplots()
        cax = ax.matshow(corr, cmap="coolwarm")
        fig.colorbar(cax)
        ax.set_xticks(range(len(corr.columns)))
        ax.set_yticks(range(len(corr.columns)))
        ax.set_xticklabels(corr.columns, rotation=90)
        ax.set_yticklabels(corr.columns)
        st.pyplot(fig)
    else:
        st.info("No hay suficientes variables num√©ricas para calcular correlaciones.")

    # =========================
    # üß† 5Ô∏è‚É£ Recomendaci√≥n de Variables
    # =========================
    st.subheader("üß† Variables candidatas para el modelo")
    st.markdown("""
    Basado en la correlaci√≥n y la disponibilidad de datos:
    - Variables con alta correlaci√≥n entre s√≠ pueden ser redundantes.
    - Las variables con baja cantidad de nulos y variabilidad alta son mejores predictoras.
    """)
    st.dataframe(
        pd.DataFrame({
            "Columna": df.columns,
            "% Nulos": (df.isnull().sum() / len(df) * 100).round(2),
            "Tipo de Dato": df.dtypes.astype(str)
        }).sort_values("% Nulos")
    )





